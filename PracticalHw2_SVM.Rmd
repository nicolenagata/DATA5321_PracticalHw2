---
title: "PracticalHw2_SVM"
output: html_document
date: "2025-04-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The second practical homework will explore the use of support vector models for classification. Using the concepts from our two lectures on support vector models, your task is to explore how health behaviors impact health outcomes. The data was collected via the National Health Interview Survey and was accessed through IPUMS Health Survey^1^. This data set contains variables regarding respondent's demographics, 5 major health conditions such as (cancer, heart disease, diabetes, heart attack and stroke) and their lifestyle and behaviors like work hours, physical activity, sleep habits, and eating habits. Details about the specific variables and the key to decoding the meaning of numeric values for each variable can be found in the codebook. 

**Your task is to predict the presence of one of these 5 diseases based on demographics and habits.**

You should explore and be creative with your answers. The main task is to perform the prediction, but you should also interrogate the data and pose questions that are interesting to you. 

You are welcome to subset the data in any way you like, e.g. only look at married couples, or only focus on children, but you should investigate the relationships among at least **5 total variables and the 3 models types (linear, radial, and polynomial kernels).** The 5 variables do not each have to be in every model. 

## Overview

**Target Variable:**

Ever told had diabetes (DIABETICEV)

**Predictor Variables:**

#### **Demographics**

-   `AGE`, `SEX`, `MARSTCUR`, `EDUC`, `REGION`

#### **Socioeconomic Status**

-   `POVERTY`, `HOURSWRK`, `SAMPWEIGHT`

#### **Body Composition**

-   `HEIGHT`, `WEIGHT`, `BMICALC`

#### **Health Behaviors**

-   Alcohol use: `ALCANYNO`, `ALCDAYSYR`

-   Smoking: `CIGDAYMO`

-   Physical activity: `MOD10DMIN`, `VIG10DMIN`

-   Sleep: `HRSLEEP`

#### **Diet**

-   Fruit & Veg: `FRUTNO`, `VEGENO`, `JUICEMNO`, `SALADSNO`

-   Processed food: `BEANNO`, `SALSAMNO`, `TOMSAUCEMNO`, `SODAPNO`, `FRIESPNO`, `PIZZANO`

-   Beverages: `SPORDRMNO`, `FRTDRINKMNO`, `COFETEAMNO`

#### **Other**

-   `CVDSHT` – COVID-19 vaccination

-   `HINOTCOVE` – Health insurance status

## Data Cleaning

First, we will import the National Health Interview Survey data set. According to Medical News Today, the onset of diabetes is most common for people ages 45 to 65, therefore we will subset the data to adults who are 45 years old or older to see what demographics and habits as older adults can predict diabetes ([Medical News Today](https://www.medicalnewstoday.com/articles/317375)).

```{r}
# import data
nhis <- read.csv("nhis_2022.csv")

# filter age over 45
library(dplyr)
nhis <- nhis %>%
  filter(AGE >= 45)
```

```{r}
### Explore Target Variables

# check classifications
table(nhis$DIABETICEV)
nhis <- nhis %>%
  filter(DIABETICEV %in% c(1, 2)) %>%
  mutate(
    DIABETICEV = ifelse(DIABETICEV == 2, 1, 0)
  )
  # recode target variable: 0 = No and 1 = Yes

# ensure target variable is treated as factor (classification)
nhis$DIABETICEV <- factor(nhis$DIABETICEV, levels = c(0, 1), labels = c("No", "Yes"))
table(nhis$DIABETICEV)
```

```{r}
### Renaming Variables
nhis <- nhis %>%
  rename(
    survey_year = YEAR,
    household_serial = SERIAL,
    variance_stratum = STRATA,
    primary_sampling_unit = PSU,
    household_id = NHISHID,
    region = REGION,
    person_number = PERNUM,
    person_id = NHISPID,
    household_number = HHX,
    sample_weight = SAMPWEIGHT,
    sample_adult_flag = ASTATFLG,
    sample_child_flag = CSTATFLG,
    age = AGE,
    sex = SEX,
    marital_status = MARSTCUR,
    education_level = EDUC,
    hours_worked_wk = HOURSWRK,
    poverty_ratio = POVERTY,
    height_in = HEIGHT,
    weight_lb = WEIGHT,
    bmi = BMICALC,
    health_insurance_status = HINOTCOVE,
    ever_had_cancer = CANCEREV,
    ever_had_heart_disease = CHEARTDIEV,
    ever_had_diabetes = DIABETICEV,
    ever_had_heart_attack = HEARTATTEV,
    ever_had_stroke = STROKEV,
    alcohol_frequency_units = ALCANYNO,
    alcohol_days_past_year = ALCDAYSYR,
    smoking_days_past_30 = CIGDAYMO,
    moderate_activity_minutes = MOD10DMIN,
    vigorous_activity_minutes = VIG10DMIN,
    fruit_intake = FRUTNO,
    vegetable_intake = VEGENO,
    juice_intake = JUICEMNO,
    salad_intake = SALADSNO,
    bean_intake = BEANNO,
    salsa_intake = SALSAMNO,
    tomato_sauce_intake = TOMSAUCEMNO,
    soda_intake = SODAPNO,
    fried_potatoes_intake = FRIESPNO,
    sports_drink_intake = SPORDRMNO,
    fruit_drink_intake = FRTDRINKMNO,
    coffee_tea_intake = COFETEAMNO,
    nonfried_potatoes_intake = POTATONO,
    pizza_intake = PIZZANO,
    hours_sleep = HRSLEEP,
    covid_vaccination = CVDSHT
  )

```

```{r}
### Data Subsets

# demographic + socioeconomic
# identify population-level disparities in diabetes risk
demo_socio <- nhis %>%
  select(ever_had_diabetes, age, sex, marital_status, education_level, poverty_ratio, hours_worked_wk, hours_sleep)

# body composition and health insurance
# weight and insurance access affects diabetes risk
body_health <- nhis %>%
  select(ever_had_diabetes, height_in, weight_lb, bmi, age, sex,alcohol_days_past_year, smoking_days_past_30)

# dietary habits
# eating factors that are associated with diabetes risk
diet <- nhis %>%
  select(ever_had_diabetes, fruit_intake, vegetable_intake, juice_intake, salad_intake,soda_intake, fried_potatoes_intake, fruit_drink_intake, pizza_intake)

# physical activity and sleep
lifestyle <- nhis %>%
  select(ever_had_diabetes, moderate_activity_minutes, vigorous_activity_minutes, hours_sleep)
```

### Linear SVM Model: Predicting Diabetes with Dietary Habits

First we will use a linear support vector machine model to predict whether or not an adult has Diabetes based on some dietary habits like their fruits and vegetable intake, juice intake, soda intake, pizza intake, and so forth. We will start with a linear model because logically there is a linear relationship with the amount of healthy/ unhealthy food in your diet and a particular blood sugar diagnosis like diabetes.

The first linear support vector machine model is tuned with a cost parameter of 0.01. The model has a training error of 0.152 and a test error of 0.156, which is a relatively low error for a first model, however the confusion matrix shows the model is only predicting no diabetes diagnosis due to that being the majority class.

To see if we can improve our model, we fit a cross validation linear support vector machine model with costs ranging from 0.1 to 1. We will also oversample our training data so that the classes of our target varaibles is more balanced. We find that the optimal model is a cost of 1. Of our 12,314 over sampled training data, 4,951 are significant in predicting a diabetes diagnosis with 2,474 being support vectors for no diabetes and 2,477 being support vectors for a diabetes diagnosis. The test error is still pretty low at 0.201.

```{r}
### SVM on Diet Subset
library(e1071)

# subset data
diet <- nhis %>%
  select(ever_had_diabetes, fruit_intake, vegetable_intake, juice_intake, salad_intake,soda_intake, fried_potatoes_intake, fruit_drink_intake, pizza_intake)

# Train-test split
set.seed(1)
index <- sample(1:nrow(diet), 0.7 * nrow(diet)) # 70/30 split
train <- diet[index, ]
test <- diet[-index, ]

# (b) Fit SVM model
svm_model <- svm(ever_had_diabetes ~ ., data = train, kernel = 'linear', cost = 0.01)

# Summary statistics of SVM model
summary(svm_model)

# (c) Training error
ypred <- predict(svm_model, newdata = train)
mean(ypred != train$ever_had_diabetes)

# Test error
ypred <- predict(svm_model, newdata = test)
mean(ypred != test$ever_had_diabetes)

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(svm_model, newdata = test)
conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
### Cross-Validation SVM
# oversample training data
library(ROSE)  
train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, N = 5000)$data

# (d) Cross-validation on SVM models
set.seed(1)
tune_model <- tune(
  svm, ever_had_diabetes ~ ., data = train_oversampled,
  kernel = "linear",
  ranges = list(cost = c(0.01, 0.1, 1))
)

# Pick best model
bestmod <- tune_model$best.model
summary(bestmod)

# (e) Training error with best model
ypred <- predict(bestmod, newdata = train_oversampled)
mean(ypred != train_oversampled$ever_had_diabetes)

# Test error with best model
ypred <- predict(bestmod, newdata = test)
mean(ypred != test$ever_had_diabetes)
```

```{r}
### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(bestmod, newdata = test)

conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
### Fried Potatoes vs Pizza Intake (Zoom into Corners)
plot(bestmod, diet, fried_potatoes_intake ~ pizza_intake)

# Bottom Right: Moderate amount of both
plot(bestmod, diet, fried_potatoes_intake ~ pizza_intake, 
     xlim = c(0, 40), ylim = c(0, 65)) 

# Top Left: Excessive amount of both
plot(bestmod, diet, fried_potatoes_intake ~ pizza_intake, 
     xlim = c(990, 1000), ylim = c(990, 1000))

# Top Right: Excessive Amount of Potatos
plot(bestmod, diet, fried_potatoes_intake ~ pizza_intake, 
     xlim = c(0, 15), ylim = c(990, 1000))

# Top Left: Excessive Amount of Pizza
plot(bestmod, diet, fried_potatoes_intake ~ pizza_intake, 
     xlim = c(994, 1000), ylim = c(0, 10))
```

```{r}
# (e) Plot the fruit drink intake vs salad intake classification
plot(bestmod, diet, fruit_drink_intake ~ salad_intake)

# Bottom Right: Moderate amount of both
plot(bestmod, diet, fruit_drink_intake ~ salad_intake, 
     xlim = c(0, 50), ylim = c(0, 65))

# Top Left: Excessive amount of both
plot(bestmod, diet, fruit_drink_intake ~ salad_intake, 
     xlim = c(990, 1000), ylim = c(990, 1000))

# Top Right: Excessive Amount of Fruit Drink
plot(bestmod, diet, fruit_drink_intake ~ salad_intake, 
     xlim = c(0, 15), ylim = c(990, 1000))

# Bottom Left: Excessive Amount of Salad
plot(bestmod, diet, fruit_drink_intake ~ salad_intake, 
     xlim = c(994, 1000), ylim = c(0, 10))

```

### Polynomial SVM Model: Predicting Diabetes by Body Composition and Health Factors

Next, we will implement a polynomial support vector machine model to predict whether or not an adult has Diabetes based on some body and health factors like age, weight, BMI, sex, alcohol and smoking use. We will start with a polynomial model as an attempt to capture some of the more complex relationships these factors might entail with a diabetes diagnosis.

The first polynomial support vector machine model is tuned with a cost parameter of 0.01 and a degree of 2. The model has a test error of 0.1896, which is a relatively low error for a first model. We also fit another polynomial model with a degree of 3, having similar results.

To see if we can improve our model, we fit a cross validation polynomial support vector machine model with costs ranging from 0.1 to 1 and degrees of 2 and 3. However, to reduce computational power, we will further subset the data to adults who are 45-65 years old, this is the most common age for adults to get diagnosed with diabetes. The optimal cost for our polynomial model is 1 with a degree of 2. Of the 6,489 points in the training data, 5,512 are significant in predicting a diabetes diagnosis, with 2,757 being no diabetes support vectors and 2,755 being a diabetes diagnosis support vector. The test error is lower than our previous models at 0.186.

```{r}
### Polynomial SVM Model (degree 2)

# (a) Split the data into training and testing sets
body_health <- nhis %>%
  select(ever_had_diabetes, height_in, weight_lb, bmi, age, sex,alcohol_days_past_year, smoking_days_past_30)

set.seed(1) 
index <- sample(1:nrow(body_health), size = 0.7 * nrow(body_health)) 
train <- body_health[index,]
test <- body_health[-index,]

train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, N = 5000)$data # over sample data

# (b) Fit the SVM model with a polynomial kernel
svm_model <- svm(ever_had_diabetes ~ ., data = train_oversampled, kernel = 'polynomial', degree = 2, cost = 0.01)

# Summary statistics of the SVM model
summary(svm_model)

# (c) Training error
ypred <- predict(svm_model, newdata = train_oversampled)
mean(ypred != train_oversampled$ever_had_diabetes)

# (d) Test error
ypred_test <- predict(svm_model, newdata = test)
mean(ypred_test != test$ever_had_diabetes) 

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(svm_model, newdata = test)
conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
### Polynomial SVM Model (degree 3)

# (a) Split the data into training and testing sets
body_health <- nhis %>%
  select(ever_had_diabetes, height_in, weight_lb, bmi, age, sex,alcohol_days_past_year, smoking_days_past_30)

set.seed(1) 
index <- sample(1:nrow(body_health), size = 0.7 * nrow(body_health)) 
train <- body_health[index,]
test <- body_health[-index,]

train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, N = 5000)$data # over sample data

# (b) Fit the SVM model with a polynomial kernel
svm_model <- svm(ever_had_diabetes ~ ., data = train_oversampled, kernel = 'polynomial', degree = 3, cost = 0.01)

# Summary statistics of the SVM model
summary(svm_model)

# (c) Training error
ypred <- predict(svm_model, newdata = train_oversampled)
mean(ypred != train_oversampled$ever_had_diabetes)

# (d) Test error
ypred_test <- predict(svm_model, newdata = test)
mean(ypred_test != test$ever_had_diabetes) 

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(svm_model, newdata = test)
conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
# (e) Cross-validation for tuning the model

# subset the data to reduce computation power
# adults between 45-65 (most common diagnosis age for adults)
adults_45_65 <- body_health %>%
  filter(age >= 45 & age <= 65)

set.seed(1) 
index <- sample(1:nrow(adults_45_65), size = 0.7 * nrow(adults_45_65)) 
train <- adults_45_65[index,]
test <- adults_45_65[-index,]
train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, seed = 1)$data

# cv model
set.seed(1)
tune_model <- tune(svm, ever_had_diabetes ~ ., 
                   data = train_oversampled, 
                   kernel = "polynomial", 
                   ranges = list(cost = c(0.01, 0.1, 1),
                                 degree = c(2,3)))

# Pick the best model based on cross-validation results
bestmod <- tune_model$best.model
summary(bestmod)

# (f) Training error for the best model:
ypred_best <- predict(bestmod, newdata = train_oversampled)
mean(ypred_best != train_oversampled$ever_had_diabetes)

# (g) Test error for the best model:
ypred_best_test <- predict(bestmod, newdata = test)
mean(ypred_best_test != test$ever_had_diabetes) 

# mse
ypred_best_test_num <- ifelse(ypred_best_test == "No", 0, 1)
test_ever_had_diabetes_num <- ifelse(test$ever_had_diabetes == "No", 0, 1)
mse_poly <- mean((ypred_best_test_num - test_ever_had_diabetes_num)^2)
mse_poly

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(bestmod, newdata = test)

conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
### Plots

# alcohol vs smoking
small_train2 <- adults_45_65 %>% select(ever_had_diabetes, alcohol_days_past_year, smoking_days_past_30)

set.seed(1)
svm_simple2 <- svm(ever_had_diabetes ~ alcohol_days_past_year + smoking_days_past_30,data = small_train2, kernel = "polynomial",cost = 1, degree = 2)

plot(svm_simple2, small_train2)
    # zoom bottom right 
plot(svm_simple2, small_train2, alcohol_days_past_year ~ smoking_days_past_30, xlim = c(0, 35), ylim = c(0, 400))
```

### Radial SVM Model: Predicting Diabetes using demographic and socio-economic factors

Next, we will implement a radialsupport vector machine model to predict whether or not an adult has Diabetes based on some demographic and socio-economic factors like marital status, education, hours worked, and amount of sleep. We will start with a radial model as an attempt to capture some of the more complex, non linear relationships these factors might entail with a diabetes diagnosis.

The first radial support vector machine model is tuned with a cost parameter of 0.01 and a tuning parameter (gamma) of 1. The model has a training error of 0.461 and a test error of 0.237, which is a relatively low error for a first model but can be imporved.

To see if we can improve our model, we fit a cross validation polynomial support vector machine model with costs ranging from 0.1 to 1 and gamma values ranging from 0.01 to 1. However, to reduce computational power, we will further subset the data to adults who are 45-65 years old, this is the most common age for adults to get diagnosed with diabetes. The optimal radial model has a cost of 1 and a gamma value of 0.5. Of the 6,489 training data points, 5,262 are significant with 2,569 being no diabetes support vector and 2,693 being diabetes diagnosis support vector. The test error is about the same as our previous models at 0.289.

```{r}
### Radial SVM Model
demo_socio <- nhis %>%
  select(ever_had_diabetes, age, sex, marital_status, education_level, poverty_ratio, hours_worked_wk, hours_sleep)

# Split the data into training and testing sets (70% train, 30% test)
set.seed(1)
index <- sample(1:nrow(demo_socio), size = 0.7 * nrow(demo_socio))
train <- demo_socio[index,]
test <- demo_socio[-index,]
train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, seed = 1)$data

# (b) Fit the SVM model
svm_model <- svm(ever_had_diabetes ~ ., data = train_oversampled, kernel = 'radial', gamma =1, cost = 0.01)

# Summary statistics of SVM model
summary(svm_model)

# (c) Training error
ypred_train <- predict(svm_model, newdata = train_oversampled)
mean(ypred_train != train_oversampled$ever_had_diabetes)

# (d) Test error
ypred_test <- predict(svm_model, newdata = test)
mean(ypred_test != test$ever_had_diabetes)

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(svm_model, newdata = test)

conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
# (e) Cross-validation for Radial SVM Model

# Subset the data to reduce computation power
# Adults between 45-65 (most common diagnosis age for adults)
adults_45_65 <- demo_socio %>%
  filter(age >= 45 & age <= 65)

# Split data into train and test sets
set.seed(1)
index <- sample(1:nrow(adults_45_65), size = 0.7 * nrow(adults_45_65)) 
train <- adults_45_65[index,]
test <- adults_45_65[-index,]
train_oversampled <- ROSE(ever_had_diabetes ~ ., data = train, seed = 1)$data

# (f) Cross-validation for tuning the radial SVM model
set.seed(1)
tune_model <- tune(svm, ever_had_diabetes ~ ., 
                   data = train_oversampled, 
                   kernel = "radial", 
                   ranges = list(cost = c(0.01, 0.1, 1),
                                 gamma = c(0.1, 0.5, 1, 2)),
                   tunecontrol = tune.control(cross = 3))

# Pick the best model based on cross-validation results
bestmod <- tune_model$best.model
tune_model$best.parameters$gamma
summary(bestmod)

# (g) Training error for the best model
ypred_best <- predict(bestmod, newdata = train_oversampled)
mean(ypred_best != train_oversampled$ever_had_diabetes)

# (h) Test error for the best model
ypred_best_test <- predict(bestmod, newdata = test)
mean(ypred_best_test != test$ever_had_diabetes)

# mse
ypred_best_test_num <- ifelse(ypred_best_test == "No", 0, 1)
test_ever_had_diabetes_num <- ifelse(test$ever_had_diabetes == "No", 0, 1)
mse_radial <- mean((ypred_best_test_num - test_ever_had_diabetes_num)^2)
mse_radial

### Confusion Matrix
true_values <- test$ever_had_diabetes  
predicted_values <- predict(bestmod, newdata = test)

conf_matrix <- table(true = true_values, pred = predicted_values)
conf_matrix
```

```{r}
### ROC CURVE 
# Predict on the test set
library(ROCR)
#fitted <- attributes(predict(bestmod, test, decision.values = TRUE))$decision.values

# Plot the ROC curve
#rocplot(-fitted, test$ever_had_diabetes, main = "Test Data ROC Curve")
```

```{r}
### Plots

# work vs sleep
small_train4 <- adults_45_65 %>% select(ever_had_diabetes, hours_worked_wk, hours_sleep)

set.seed(1)
svm_simple4 <- svm(ever_had_diabetes ~ hours_worked_wk + hours_sleep, 
                   data = small_train4, 
                   kernel = "radial", 
                   gamma = 1, cost = 0.1)

# plot
plot(svm_simple4, small_train4, hours_worked_wk ~ hours_sleep)
  # zoom
plot(svm_simple4, small_train4, hours_worked_wk ~ hours_sleep,
     xlim = c(0, 12), ylim = c(0, 80))
```
